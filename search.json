[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Controle de processos βAR(1)",
    "section": "",
    "text": "Introdução\nO presente trabalho visa aplicar métodos de controle estatístico de processos em séries temporais para detectar mudanças.\nCom o foco em séries temporais autorregressivas de ordem 1 com distribuição Beta, denominadas βAR(1), o objetivo é detectar mudanças em um processo simulado.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "distribuicao-beta.html",
    "href": "distribuicao-beta.html",
    "title": "\n1  Distribuição Beta\n",
    "section": "",
    "text": "1.1 Modelos βAR(1)\nA distribuição Beta é uma distribuição de probabilidade contínua definida no intervalo \\((0, 1)\\), com dois parâmetros \\(p\\) e \\(q\\), e função densidade de probabilidade dada por:\n\\[\n\\pi(y | p, q) = \\frac{\\Gamma(p + q)}{\\Gamma(p)\\Gamma(q)} y^{p - 1} (1 - y)^{q - 1}, \\quad 0 &lt; y &lt; 1\n\\]\nonde \\(\\Gamma(\\cdot)\\) é a função gama e \\(p, q &gt; 0\\).\nEssa distribuição é bastante flexível para modelar proporções, taxas e probabilidades.\nSua média e variância são dadas por:\n\\[\nE(y) = \\frac{p}{p + q} \\quad \\text{e} \\quad \\text{Var}(y) = \\frac{pq}{(p + q)^2(p + q + 1)}\n\\]\nO βAR(1) é um modelo de séries temporais autorregressiva de ordem 1 com distribuição Beta.\nO modelo ARMA com distribuição Beta foi proposto por Rocha e Cribari-Neto em:\nMatematicamente falando, seja βAR(1) o modelo de séries temporais autorregressivo de ordem 1 com distribuição Beta, e sejam a série temporal \\(Y_{t} = \\left\\{y_{1}, y_{2}, \\ldots, y_{t} | y_{n} \\in (0, 1)\\right\\}\\), o conjunto \\(l\\)-dimensional de covariáveis \\(\\mathbf{X_{t}}\\), e o vetor de parâmetros \\(\\beta = \\left\\{\\beta_{1}, \\beta_{2}, \\ldots, \\beta_{l}\\right\\}\\), temos o modelo βAR(1):\n\\[\ng(\\mu_t) = \\alpha + \\mathbf{X_t'}\\beta + \\phi \\left(g(Y_{t-1}) - \\mathbf{X_{t-1}\\beta}\\right)\n\\]\nOnde \\(g: (0,1) \\rightarrow \\mathbb{R}\\) é a função de ligação (usualmente utiliza-se a função \\(\\text{logit}\\)), \\(\\alpha\\) é o intercepto, \\(\\phi\\) é o parâmetro de autorregressão, e \\(\\mu_t\\) é a média condicional da distribuição Beta.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuição Beta</span>"
    ]
  },
  {
    "objectID": "distribuicao-beta.html#modelos-βar1",
    "href": "distribuicao-beta.html#modelos-βar1",
    "title": "\n1  Distribuição Beta\n",
    "section": "",
    "text": "Beta autoregressive moving average models. 20091.\nErratum to: Beta autoregressive moving average models. 20172.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuição Beta</span>"
    ]
  },
  {
    "objectID": "distribuicao-beta.html#controle-de-processos",
    "href": "distribuicao-beta.html#controle-de-processos",
    "title": "\n1  Distribuição Beta\n",
    "section": "\n1.2 Controle de processos",
    "text": "1.2 Controle de processos\nUtilizaremos o princípio de que, os resíduos de uma série temporal, como a βAR(1), quando modelada corretamente, são independentes e normalmente distribuídos, possuindo média zero e variância constante.\nDesta forma, quando o processo sofre uma mudança, espera-se que estes resíduos não sejam mais independentes e que sua média e variância sejam diferentes de quando o processo estava sob controle. Assim, podemos utilizar métodos de controle de processos para detectar essas mudanças.\n\n1.2.1 Simulação\nPara simular o processo, utilizaremos um modelo βAR(1) a partir da biblioteca BTSR3.\nCom os seguintes parâmetros da Fase I:\n\n\n\\(n_{0} = 100\\) a quantidade de observações.\n\n\\(\\Phi_0 = 0.2\\) o coeficiente de autorregressão.\n\n\\(\\alpha = 0\\) o intercepto.\n\n\\(\\nu = 20\\) o parâmetro de precisão/dispersão (20 é o valor padrão que o pacote BTSR3 utiliza).\n\nE na Fase II:\n\n\n\\(n_{1} = 200\\).\n\n\\(\\Phi_1 = 0.2, 0.3, \\ldots, 0.6\\).\n\n\\(\\alpha = 0\\).\n\n\\(\\nu = 20\\).\n\nSob uma perspectiva de teste de hipóteses, temos:\n\n\n\\(H_0\\): o processo está sob controle.\n\n\\(H_1\\): o processo sofreu uma mudança.\n\nUtilizaremos, neste trabalho, um nível de significância de 0.05 para os testes de hipóteses, o que nos dá um quantil de 1.96 para a distribuição normal padrão.\nPor fim, será utilizada a biblioteca qcc4 para a análise dos Pontos Fora de Controle (PFC).\n\n1.2.2 Monte Carlo\nPara avaliar o desempenho do teste de hipóteses, realizaremos um experimento de Monte Carlo.\n\n1.2.2.1 Validação\nVerificando a nossa implementação, percebemos que a variância da estimativa de \\(\\phi\\) diminui conforme o tamanho da amostra aumenta, o que é esperado.\nCom isso podemos concluir que a nossa implementação está correta.\n\nteste_montecarlo &lt;- cache_dados(\n  \"teste-montecarlo\",\n  function() {\n    gerador_monte_carlo(\n      parametros = list(n1 = c(\n        rep(25, 20), rep(50, 20), rep(100, 20), rep(200, 20)\n      )),\n      numero_de_execucoes = 1\n    ) %&gt;%\n      select(n1, f1_phi, f2_phi) %&gt;%\n      mutate(\n        # Calcula a diferença entre os valores de phi\n        # `phi_parametro`: valor de phi definido para a amostra de controle\n        # `f1_phi`: valor de phi estimado para a amostra de controle. Espera-se que seja igual a `phi_parametro`\n        diferenca = f1_phi - phi_parametro\n      )\n  }\n)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuição Beta</span>"
    ]
  },
  {
    "objectID": "distribuicao-beta.html#referências",
    "href": "distribuicao-beta.html#referências",
    "title": "\n1  Distribuição Beta\n",
    "section": "\n1.3 Referências",
    "text": "1.3 Referências\n1. ROCHA, A. V., CRIBARI-NETO, F. Beta autoregressive moving average models. TEST 18, 529–545 (2009). DOI: 10.1007/s11749-008-0112-z\n2. ROCHA, A. V., CRIBARI-NETO, F. Erratum to: Beta autoregressive moving average models. TEST 26, 451–459 (2017). DOI: 10.1007/s11749-017-0528-4\n3. PRASS, T. S., et. al. BTSR: Bounded Time Series Regression. R package version 0.1.5. 2023-09-22. DOI: 10.32614/CRAN.package.BTSR\n4. SCRUCCA, L., et. al. qcc: Quality Control Charts. R package version 2.7. 2017-07-09. DOI: 10.32614/CRAN.package.qcc\n5. MONTGOMERY, D. C. Introduction to Statistical Quality Control. 2013. John Wiley & Sons.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuição Beta</span>"
    ]
  },
  {
    "objectID": "ceq-residuos.html",
    "href": "ceq-residuos.html",
    "title": "\n2  CEQ usando resíduos\n",
    "section": "",
    "text": "2.1 EWMA\nO EWMA (Exponential Weighted Moving Average – Média Móvel Exponencialmente Ponderada) é um método de controle de processos que utiliza uma média móvel ponderada exponencialmente para detectar mudanças no processo (MONTGOMERY, 2009)5.\nEle parte de uma ideia simples: ao invés de usarmos apenas a última amostra, usamos uma média ponderada de todas as amostras anteriores. A ponderação é exponencial, o que significa que amostras mais antigas têm menos peso que amostras mais recentes.\nMatematicamente, a média EWMA é dada por:\n\\[\nz_i = \\lambda y_i + (1 - \\lambda) z_{i-1}\n\\]\nOnde, \\(z_i\\) é a estatística de controle no instante \\(i\\), \\(y_i\\) é a observação no instante \\(i\\), \\(\\lambda\\) é o fator de suavização e \\(z_{i-1}\\) é a estatística de controle no instante anterior. O valor inicial de \\(z_0\\) é definido como a média do processo, tal que \\(z_0 = \\mu_0\\).\nOutro fato importante, é que, uma vez que o EWMA é uma média ponderada de todas as amostras anteriores, ele é pouco sensível à suposição de normalidade dos dados.\nA estatística, \\(z_i\\), é, então, comparada com os limites de controle, \\(\\text{LCS}\\) e \\(\\text{LCI}\\), definidos como:\n\\[\n\\text{LC} = \\mu_0 \\pm L \\sigma \\sqrt{\\frac{\\lambda}{2 - \\lambda} \\left[1 - \\left(1 - \\lambda\\right)^{2i}\\right]}\n\\]\nAqui, utilizaremos o pacote qcc4 para implementar o EWMA.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>CEQ usando resíduos</span>"
    ]
  },
  {
    "objectID": "ceq-residuos.html#ewma",
    "href": "ceq-residuos.html#ewma",
    "title": "\n2  CEQ usando resíduos\n",
    "section": "",
    "text": "2.1.1 O fator λ\nO \\(\\lambda\\) é uma constante definida no intervalo \\((0, 1]\\), quanto mais próximo de 1, mais peso é dado à amostra mais recente, tanto que, quando \\(\\lambda = 1\\), teremos a carta de controle de Shewhart, pois a média EWMA será igual à média das amostras.\nPara Montgomery (2009)5, em geral, valores de \\(\\lambda\\) entre 0.05 e 0.25 são recomendados. No entanto, esta escolha depende do tipo de processo e do grau de sensibilidade desejado.\n\newma_qcc &lt;- function(amostra_inicial,\n                     lambda,\n                     amostra_subsequente = NULL,\n                     nsigmas = 1.96) {\n  arguments &lt;- list(\n    amostra_inicial,\n    lambda = lambda,\n    nsigmas = nsigmas,\n    plot = F\n  )\n\n  if (!is.null(amostra_subsequente)) {\n    arguments$newdata &lt;- amostra_subsequente\n  }\n\n  ew &lt;- do.call(ewma, arguments)\n\n  registros &lt;- if (is.null(amostra_subsequente)) {\n    seq(1, length(amostra_inicial))\n  } else {\n    seq(length(amostra_inicial) + 1, length(amostra_inicial) + length(amostra_subsequente))\n  }\n\n  ewma &lt;- as.numeric(ew$y[registros])\n  LI &lt;- ew$limits[, 1][registros]\n  LS &lt;- ew$limits[, 2][registros]\n  fora_de_controle &lt;- ewma &lt; LI | ewma &gt; LS\n  total_fora_de_controle &lt;- sum(fora_de_controle, na.rm = TRUE)\n  fracao_fora_de_controle &lt;- total_fora_de_controle / length(ewma)\n  list(\n    ewma = ewma,\n    LI = LI,\n    LS = LS,\n    fora_de_controle = fora_de_controle,\n    total_fora_de_controle = total_fora_de_controle,\n    fracao_fora_de_controle = fracao_fora_de_controle\n  )\n}\n\n\n2.1.2 Simulação\nVamos buscar o melhor valor de \\(\\lambda\\) para o EWMA, para um nível de significância constante, \\(\\alpha = 0.05\\).\n\newma_monte_carlo &lt;- cache_dados(\"simulacao-ewma\", function() {\n  gerador_monte_carlo(parametros = list(lambda = seq(0.1, 0.9, by = 0.1))) %&gt;%\n    mutate(\n      qcc = list(ewma_qcc(f1_residuos, lambda, f2_residuos)),\n      ewma = list(qcc$ewma),\n      LI = list(qcc$LI),\n      LS = list(qcc$LS),\n      fora_de_controle = list(qcc$fora_de_controle),\n      total_fora_de_controle = qcc$total_fora_de_controle,\n      fracao_fora_de_controle = qcc$fracao_fora_de_controle\n    ) %&gt;%\n    select(-qcc)\n})\n\newma_monte_carlo$lambda &lt;- as.factor(ewma_monte_carlo$lambda)\n\n\n2.1.2.1 Resumo\nResumo da fração de pontos fora de controle (FPFC) para diferentes valores de \\(\\lambda\\) e \\(\\Phi_2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.2.2 Cartas para λ = 0.8\n\nVamos analisar o EWMA para \\(\\lambda = 0.8\\). Aqui, vamos considerar apenas a primeira execução.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>CEQ usando resíduos</span>"
    ]
  },
  {
    "objectID": "ceq-residuos.html#ewma-ar",
    "href": "ceq-residuos.html#ewma-ar",
    "title": "\n2  CEQ usando resíduos\n",
    "section": "\n2.2 EWMA-AR",
    "text": "2.2 EWMA-AR\n\nNota do autor: O EWMA-AR é uma extensão do EWMA que utiliza um modelo autorregressivo para prever a próxima observação. Como será apresentado a seguir, o EWMA-AR possuim um poder muito menor que o EWMA para detectar mudanças no processo. Por consequência disso, o EWMA-AR é tratado aqui apenas como uma curiosidade.\n\nSegundo Montgomery (2009)5, o EWMA-AR é uma extensão do EWMA que utiliza um modelo autorregressivo para prever a próxima observação.\nAssim, temos que \\(\\lambda \\in (0, 1]\\), sendo que, a previsão para a observação \\(x_{t+1}\\) é dada por \\(\\hat{x}_{t+1}(t)=z_{t} = \\lambda x_t + (1 - \\lambda) z_{t-1}\\).\n\n2.2.1 Otimizando λ\nDe acordo com Montgomery (2009)5, podemos encontrar um valor ótimo para \\(\\lambda\\) através da minimização da soma dos quadrados dos resíduos.\nE, ainda, temos que os erros de previsão são dados por \\(e_t = x_t - \\hat{x}_t(t-1)\\) conforme a Eq. 10.16 (Montgomery, 2009)5.\nOu, de outra forma\n\\[\n\\hat{\\lambda} = \\min \\left( \\underset{\\lambda\\in(0,1]}{\\arg\\min}\\,\\text{Err}(\\lambda) \\right)\n\\]\nonde \\(\\hat{\\lambda}\\) é o \\(\\lambda\\) ótimo por simulação, e \\(\\text{Err}(\\lambda) = \\sum_{t=1}^{n} e_t^2\\).\nSegundo, também Montgomery (2009)5, podemos estimar o valor de \\(\\sigma^2\\) para o modelo EWMA-AR como \\(\\sigma^2 = \\frac{\\sum (\\text{err}_i^2|_\\lambda)}{n}\\). Onde \\(\\text{err}|_\\lambda\\) são os resíduos do modelo EWMA-AR para o melhor valor de \\(\\lambda\\) encontrado.\n\n# Função para computar resíduos do EWMA-AR\newma_ar_residuos &lt;- function(dados, ewma) {\n  n &lt;- length(dados)\n  residuos &lt;- numeric(n)\n  residuos[1] &lt;- dados[1]\n  for (i in 2:n) {\n    residuos[i] &lt;- dados[i] - ewma[i - 1]\n  }\n  return(residuos)\n}\n\n# Função para computar o EWMA-AR\newma_ar &lt;- function(dados,\n                    lambda,\n                    x0 = NULL,\n                    desvio = NULL) {\n  desv &lt;- ifelse(is.null(desvio), sqrt(sd(dados)), desvio)\n  n &lt;- length(dados)\n  final &lt;- ifelse(is.null(x0), n, n + 1)\n\n  ewma_serie &lt;- numeric(final)\n  ewma_serie[1] &lt;- ifelse(is.null(x0), dados[1], x0)\n  for (i in 2:final) {\n    ewma_serie[i] &lt;- lambda * dados[i] + (1 - lambda) * ewma_serie[i - 1]\n  }\n\n  ewma &lt;- ewma_serie[ifelse(is.null(x0), 1, 2):final]\n  LI &lt;- ewma - 1.96 * desv\n  LS &lt;- ewma + 1.96 * desv\n  fora_de_controle &lt;- dados &lt; LI | dados &gt; LS\n  total_fora_de_controle &lt;- sum(fora_de_controle, na.rm = TRUE)\n  fracao_fora_de_controle &lt;- total_fora_de_controle / length(ewma)\n\n  return(\n    list(\n      ewma = ewma,\n      residuos = ewma_ar_residuos(dados, ewma_serie),\n      LI = LI,\n      LS = LS,\n      fora_de_controle = fora_de_controle,\n      total_fora_de_controle = total_fora_de_controle,\n      fracao_fora_de_controle = fracao_fora_de_controle\n    )\n  )\n}\n\n\nlambda_otimo_optimize &lt;- function(amostra_inicial) {\n  lambda &lt;- NA\n  minimo &lt;- Inf\n  for (x in c(seq(0.01, 0.1, by = 0.01), seq(0.1, 0.9, by = 0.1))) {\n    ew &lt;- ewma_ar(amostra_inicial, lambda = x)\n\n    erros &lt;- ew$residuos\n    soma_quadrados &lt;- sum(erros^2)\n    if (soma_quadrados &lt; minimo) {\n      minimo &lt;- soma_quadrados\n      lambda &lt;- x\n    }\n  }\n  return(list(lambda = lambda, minimo = minimo))\n}\n\newmar_lambda_otimo &lt;- cache_dados(\"ewmaar-lambda-otimo\", \\() {\n  data.frame(id = 1:100) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n      f1_amostra = list(barma.sim(n = n1, phi = phi_parametro)),\n      f1_phi = list(barma.phi_estimado(f1_amostra)),\n      f1_residuos = list(barma.residuos(f1_amostra, f1_phi)),\n      ewma_ar = list(lambda_otimo_optimize(f1_residuos)),\n      lambda = ewma_ar$lambda,\n      minimo = ewma_ar$minimo\n    ) %&gt;%\n    select(-ewma_ar)\n})\n\n\n\n\n\n\n\nPor simulação encontramos um \\(\\lambda\\) ótimo de \\(\\sim 0.07\\). Com erro médio de \\(\\sim 22\\), o que nos dá um desvio de \\(22 / 100 \\simeq 0.2\\).\n\n2.2.2 Simulação\n\newmaar_monte_carlo &lt;- cache_dados(\"simulacao-ewma-ar\", function() {\n  gerador_monte_carlo(parametros = list(lambda = c(0.1, 0.07, 0.03))) %&gt;%\n    mutate(\n      ewma_ar = list(ewma_ar(\n        f2_controle, lambda, f1_amostras[n1], sd(f1_amostras)\n      )),\n      ewma = list(ewma_ar$ewma),\n      LI = list(ewma_ar$LI),\n      LS = list(ewma_ar$LS),\n      fora_de_controle = list(ewma_ar$fora_de_controle),\n      total_fora_de_controle = ewma_ar$total_fora_de_controle,\n      fracao_fora_de_controle = ewma_ar$fracao_fora_de_controle\n    ) %&gt;%\n    select(-ewma_ar)\n})\n\newmaar_monte_carlo$lambda &lt;- as.factor(ewmaar_monte_carlo$lambda)\n\newmaar_monte_carlo_resumo &lt;- ewmaar_monte_carlo %&gt;%\n  group_by(lambda, f2_phi) %&gt;%\n  summarise(\n    mean = mean(fracao_fora_de_controle),\n    min = min(fracao_fora_de_controle),\n    max = max(fracao_fora_de_controle),\n    .groups = \"drop\"\n  )\n\ndatatable(\n  ewmaar_monte_carlo_resumo %&gt;%\n    mutate(across(where(is.numeric), \\(x) round(x, digits = 4))),\n  caption = \"Pontos fora de controle\",\n  colnames = c(\n    \"Valores de λ\", \"Valores de Φ₂\", \"Média\", \"Mínimo\", \"Máximo\"\n  )\n)\n\n\n\n\n\nVamos analisar o EWMA-AR para \\(\\lambda = 0.07\\). O resultado encontrado anteriormente.\nVamos, além disso, comparar com o EWMA realizado a partir dos resíduos do modelo βAR(1).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>CEQ usando resíduos</span>"
    ]
  },
  {
    "objectID": "ceq-residuos.html#cusum",
    "href": "ceq-residuos.html#cusum",
    "title": "\n2  CEQ usando resíduos\n",
    "section": "\n2.3 CUSUM",
    "text": "2.3 CUSUM\nO CUSUM (Cumulative Sum – Soma Acumulada) é um método de controle de processos que utiliza a soma acumulada dos resíduos para detectar mudanças no processo (MONTGOMERY, 2009)5.\nNeste método são definidas duas constantes, \\(H\\) e \\(K\\), que representam o tamanho da mudança que se deseja detectar e a sensibilidade do método, respectivamente. As estatísticas de controle, sendo duas, são definidas como:\n\\[\n\\begin{matrix}\n\\text{C}^+_i & = & \\max\\left[0, x_i - (\\mu_0 + K) + C^+_{i-1}\\right] \\\\\n\\text{C}^-_i & = & \\max\\left[0, (\\mu_0 - K) - x_i + C^-_{i-1}\\right] \\\\\n\\end{matrix}\n\\]\nonde \\(x_i\\) é a observação no instante \\(i\\), \\(\\mu_0\\) é a média do processo, \\(C^+_0 = C^-_0 = 0\\) e \\(i = 1, 2, \\ldots, n\\).\nA constante \\(K\\), chamada de valor de referência, geralmente, segundo MONTGOMERY (2009)5, é definida como a metade entre o \\(\\mu_0\\) alvo e o valor fora de controle de média \\(\\mu_1\\) que queremos detectar.\nJá a constante \\(H\\), chamada de limite de decisão, é definida como o valor que a estatística de controle deve atingir para podermos detectar a mudança no processo. Para MONTGOMERY (2009)5, um valor razoável para \\(H\\) é \\(5\\sigma\\). Assim, se \\(\\text{C}^+_i \\geq H\\) ou \\(\\text{C}^-_i \\leq -H\\), então o processo está fora de controle.\nAqui, utilizaremos o pacote qcc4 para implementar o CUSUM.\n\ncusum_qcc &lt;- function(amostra_inicial,\n                      desvio_detectavel = 1,\n                      intervalo_de_decisao = 5,\n                      amostra_subsequente = NULL) {\n  arguments &lt;- list(\n    data = amostra_inicial,\n    se.shift = desvio_detectavel,\n    decision.interval = intervalo_de_decisao,\n    plot = F\n  )\n\n  if (!is.null(amostra_subsequente)) {\n    arguments$newdata &lt;- amostra_subsequente\n  }\n\n  cu &lt;- do.call(cusum, arguments)\n\n  # registros &lt;- if (is.null(amostra_subsequente)) {\n  #   seq(1, nH0)\n  # } else {\n  #   seq(nH0 + 1, nH0 + nH1)\n  # }\n  registros &lt;- if (is.null(amostra_subsequente)) {\n    seq(1, length(amostra_inicial))\n  } else {\n    seq(length(amostra_inicial) + 1, length(amostra_inicial) + length(amostra_subsequente))\n  }\n  pos &lt;- cu[[\"pos\"]][registros]\n  neg &lt;- cu[[\"neg\"]][registros]\n  fora_de_controle_pos &lt;- pos &gt; intervalo_de_decisao\n  fora_de_controle_neg &lt;- neg &lt; -intervalo_de_decisao\n  fora_de_controle &lt;- ifelse(\n    fora_de_controle_pos,\n    fora_de_controle_pos,\n    fora_de_controle_neg\n  )\n  total_fora_de_controle &lt;- sum(fora_de_controle)\n  fracao_fora_de_controle &lt;- total_fora_de_controle / length(registros)\n\n  list(\n    pos = pos,\n    neg = neg,\n    fora_de_controle_pos = fora_de_controle_pos,\n    fora_de_controle_neg = fora_de_controle_neg,\n    fora_de_controle = fora_de_controle,\n    total_fora_de_controle = total_fora_de_controle,\n    fracao_fora_de_controle = fracao_fora_de_controle\n  )\n}\n\n\n2.3.1 Simulação\nVamos buscar o melhor valor de \\(K\\) e \\(H\\) para o CUSUM, para um nível de significância constante.\n\ncomb_cusum &lt;- cache_dados(\"simulacao-cusum-k-h\", function() {\n  gerador_monte_carlo(parametros = expand.grid(\n    desvio_detectavel = seq(0.6, 1.8, by = 0.2),\n    intervalo_de_decisao = seq(3, 6, by = 1)\n  )) %&gt;%\n    mutate(\n      qcc = list(\n        cusum_qcc(\n          f1_residuos,\n          desvio_detectavel = desvio_detectavel,\n          intervalo_de_decisao = intervalo_de_decisao,\n          amostra_subsequente = f2_residuos\n        )\n      ),\n      pos = list(qcc$pos),\n      neg = list(qcc$neg),\n      fora_de_controle_pos = list(qcc$fora_de_controle_pos),\n      fora_de_controle_neg = list(qcc$fora_de_controle_neg),\n      fora_de_controle = list(qcc$fora_de_controle),\n      total_fora_de_controle = qcc$total_fora_de_controle,\n      fracao_fora_de_controle = qcc$fracao_fora_de_controle\n    ) %&gt;%\n    select(-qcc)\n})\n\ncomb_cusum$parametro &lt;- as.factor(paste0(comb_cusum$desvio_detectavel, \";\", comb_cusum$intervalo_de_decisao))\n\n\n2.3.1.1 Resumo\nResumo da fração de pontos fora de controle (FPFC) para diferentes valores de \\(K\\) e \\(H\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.1.2 Cartas para K = 1 e H = 4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>CEQ usando resíduos</span>"
    ]
  },
  {
    "objectID": "ceq-residuos.html#ewma-vs.-cusum",
    "href": "ceq-residuos.html#ewma-vs.-cusum",
    "title": "\n2  CEQ usando resíduos\n",
    "section": "\n2.4 EWMA vs. CUSUM",
    "text": "2.4 EWMA vs. CUSUM\nVamos comparar os melhores valores de \\(\\lambda\\) e \\(K/H\\) para o EWMA e CUSUM, respectivamente.\n\n\n\n\n\n\n\nObserva-se que o CUSUM possui mais poder de detecção que o EWMA, mas, em compensação, possui uma variabilidade maior.\n\n\n2.4.1 ARL\nO ARL (Average Run Length – Comprimento Médio de Execução) é uma medida de desempenho de um método de controle de processo. É definido como o número médio de observações necessárias para detectar uma mudança no processo. E pode ser calculado como\n\\[\n\\text{ARL} = \\frac{1}{\\text{FPR}}\n\\]\nonde FPR é a taxa de falsos positivos, ou seja, a fração de vezes que o método detecta uma mudança no processo quando não há. Ou seja, é a taxa de pontos fora de controle quando o processo está sob controle.\nVamos ver como o ARL se comporta para os melhores valores de \\(\\lambda\\) e \\(K/H\\) encontrados.\n\narl &lt;- function(fpr) {\n  return(1 / fpr)\n}\n\narl &lt;- dados_resumo_ %&gt;%\n  filter(f2_phi == 0.2) %&gt;%\n  group_by(parametro, algoritmo) %&gt;%\n  summarise(\n    mean = mean(mean),\n    min = min(min),\n    max = max(max),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    arl = ceiling(1 / mean)\n  )\n\ndatatable(\n  arl %&gt;%\n    mutate(across(where(is.numeric), \\(x) round(x, digits = 4))),\n  caption = \"ARL\",\n  colnames = c(\n    \"Parâmetro\",\n    \"Algoritmo\",\n    \"Média\",\n    \"Mínimo\",\n    \"Máximo\",\n    \"ARL\"\n  )\n)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>CEQ usando resíduos</span>"
    ]
  },
  {
    "objectID": "ceq-residuos.html#referências",
    "href": "ceq-residuos.html#referências",
    "title": "\n2  CEQ usando resíduos\n",
    "section": "\n2.5 Referências",
    "text": "2.5 Referências\n1. ROCHA, A. V., CRIBARI-NETO, F. Beta autoregressive moving average models. TEST 18, 529–545 (2009). DOI: 10.1007/s11749-008-0112-z\n2. ROCHA, A. V., CRIBARI-NETO, F. Erratum to: Beta autoregressive moving average models. TEST 26, 451–459 (2017). DOI: 10.1007/s11749-017-0528-4\n3. PRASS, T. S., et. al. BTSR: Bounded Time Series Regression. R package version 0.1.5. 2023-09-22. DOI: 10.32614/CRAN.package.BTSR\n4. SCRUCCA, L., et. al. qcc: Quality Control Charts. R package version 2.7. 2017-07-09. DOI: 10.32614/CRAN.package.qcc\n5. MONTGOMERY, D. C. Introduction to Statistical Quality Control. 2013. John Wiley & Sons.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>CEQ usando resíduos</span>"
    ]
  }
]